---
title: "CARET_Lab"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Package loading
```{r}
library(caret)
install.packages("skimr")
library(skimr)
```

Load Data
```{r}
# attach the iris dataset to the environment
data(iris)
# rename the dataset
dataset <- iris
```

Task1: Create a Validation/Training Dataset
You need to split the loaded dataset into two, 80% of which we will use to train our models and 20% that we will hold back as a validation dataset.
Hint: use createDataPartition function
```{r}
set.seed(42)
# Use createDataPartition to split the data into training and validation sets
index <- createDataPartition(dataset$Species, p = 0.8, list = FALSE)

# Create the training set
train_data <- dataset[index, ]

# Create the validation set
validation_data <- dataset[-index, ]
```

Task2: Summarize Dataset
Use skimr library to summarize the dataset
```{r}
# Summarize the dataset
summary_result <- skim(dataset)
# Print the summary result
summary_result
```

Task3: split input and output
 It is the time to seperate the input attributes and  the output attributes. call the inputs attributes x and the output attribute (or class) y.
```{r}
# Separate input (x) and output (y)
x <- dataset[, 1:4]
y <- dataset$Species

# Display the first few rows of x and y
head(x)
head(y)
```

Task4: Train Control for Validation Test

We will use 10-fold crossvalidation to estimate accuracy.
```{r}
# Run algorithms using 10-fold cross validation
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
```

Task5: Model Training
Train 5 different algorithms using 'train' function:

- Linear Discriminant Analysis (LDA)
- Classification and Regression Trees (CART).
- k-Nearest Neighbors (kNN).
- Support Vector Machines (SVM) with a linear kernel.
- Random Forest (RF)

```{r}
install.packages(c("caret", "MASS", "rpart", "class", "e1071", "randomForest"))
library(caret)
library(MASS)          # For LDA
library(rpart)         # For CART
library(class)         # For kNN
library(e1071)         # For SVM
library(randomForest)  # For RF
```
```{r}
# Linear Discriminant Analysis (LDA)
lda_model <- train(x, y, method = "lda", metric = metric, trControl = control)
```
```{r}
# Classification and Regression Trees (CART)
cart_model <- train(x, y, method = "rpart", metric = metric, trControl = control)
```
```{r}
# k-Nearest Neighbors (kNN)
knn_model <- train(x, y, method = "knn", metric = metric, trControl = control)
```
```{r}
# Support Vector Machines (SVM) with a linear kernel
svm_model <- train(x, y, method = "svmLinear", metric = metric, trControl = control)
```
```{r}
# Random Forest (RF)
rf_model <- train(x, y, method = "rf", metric = metric, trControl = control)
```

Task6: Select the Best Model
We now have 5 models and accuracy estimations for each. We need to compare the models to each other and select the most accurate.
Use resamples function to complete this task

```{r}
models <- list(
  LDA = lda_model,
  CART = cart_model,
  kNN = knn_model,
  SVM = svm_model,
  RF = rf_model
)

# Compare models using resamples
resamps <- resamples(models)

# Summarize the results
summary(resamps)

# Visualize the results
dotplot(resamps)
```
What was the most accurate model?
LDA

Task7: Make Prediction (Confusion Matrix)
Now we want to get an idea of the accuracy of the best model on our validation set. Use 'predict' and confusionMatrix functions to complete this task.

```{r}
# Make predictions using the LDA model
predictions <- predict(lda_model, newdata = validation_data)

# Create a confusion matrix
conf_matrix <- confusionMatrix(predictions, validation_data$Species)

# Print the confusion matrix
print(conf_matrix)
```

